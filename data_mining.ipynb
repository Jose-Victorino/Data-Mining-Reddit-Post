{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bce4cdce",
   "metadata": {},
   "source": [
    "### SCRAPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866e8c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reddit mining using PRAW\n",
    "import praw\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "  client_id='6NE27-qV7tGX07FuBfik3w',\n",
    "  client_secret='fauqCWKne1OXmmtzPIABkNW57DFyZA',\n",
    "  user_agent='Comment scraper'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330968e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import html\n",
    "from langdetect import detect, LangDetectException\n",
    "\n",
    "subreddit_names = ['Anxiety', 'mentalhealth']\n",
    "posts_data = []\n",
    "total_comments = 0\n",
    "target_comments = 5000\n",
    "mod_keywords = ['announcement', 'rules', 'mod', 'moderator', 'admin', 'clarification', 'faq', 'meta', 'update', 'policy']\n",
    "\n",
    "def is_mod_post(post):\n",
    "  if post.distinguished in ['moderator', 'admin']:\n",
    "    return True\n",
    "  text = (post.title + \" \" + post.selftext).lower()\n",
    "  return any(keyword in text for keyword in mod_keywords)\n",
    "\n",
    "def is_mod_comment(comment):\n",
    "  if comment.distinguished in ['moderator', 'admin']:\n",
    "    return True\n",
    "  text = comment.body.lower()\n",
    "  return any(keyword in text for keyword in mod_keywords)\n",
    "\n",
    "def clean_text(text):\n",
    "  if not text:\n",
    "    return \"\"\n",
    "  text = html.unescape(text)                                                  # Decode HTML entities\n",
    "  text = re.sub(r'\\[deleted\\]|[removed]', '', text, flags = re.IGNORECASE)    # remove [deleted]/[removed]\n",
    "  text = re.sub(r'httpS+|wwwS+', '', text)                                    # Remove URLs\n",
    "  text = re.sub(r'&w+;', '', text)                                            # Remove encoded HTML symbols\n",
    "  text = re.sub(r'u/w+|r/w+', '', text)                                       # Remove mentions\n",
    "  text = re.sub(r'>.*n?', '', text)                                           # Remove blockquotes\n",
    "  text = re.sub(r'*+', '', text)                                              # Remove markdown asterisks\n",
    "  text = re.sub(r'[rn\\t]', ' ', text)                                         # Normalize whitespace\n",
    "  text = re.sub(r'[^a-zA-Z\\s\\.,!?\\'\":;()\\[\\]{}\\-]', '', text)                 # Remove numbers, unicode, & symbols\n",
    "  text = re.sub(r'[^\\x00-\\x7F]+', '', text)                                   # Remove non-ASCII characters\n",
    "  text = re.sub(r'\\s+([.,!?;:])', r'\\1', text)                                # Remove spaces before punctuation\n",
    "  text = re.sub(r'([!?])\\1{2,}', r'\\1\\1\\1', text)                             # Limit repeated punctuation to max 3\n",
    "  text = re.sub(r'(\\.\\s*){2,}', '...', text)                                  # Normalize ellipses\n",
    "  text = re.sub(r'\\.{4,}', '...', text)                                       # Normalize ellipses\n",
    "  text = re.sub(r'\\s{2,}', ' ', text)                                         # Collapse multiple spaces\n",
    "  return text.strip().lower()\n",
    "\n",
    "def is_english(text):\n",
    "  try:\n",
    "    if len(text) < 20:\n",
    "      return False\n",
    "    return detect(text) == 'en'\n",
    "  except LangDetectException:\n",
    "    return False\n",
    "\n",
    "for sub_name in subreddit_names:\n",
    "  sub_comments = 0\n",
    "  \n",
    "  for submission in reddit.subreddit(sub_name).new(limit = None):\n",
    "    if sub_comments >= target_comments / len(subreddit_names):\n",
    "      break\n",
    "\n",
    "    if is_mod_post(submission):\n",
    "      continue\n",
    "\n",
    "    submission.comments.replace_more(limit = 0)\n",
    "    comments = []\n",
    "\n",
    "    for comment in submission.comments.list():\n",
    "      if is_mod_comment(comment):\n",
    "        continue\n",
    "\n",
    "      clean_body = clean_text(comment.body)\n",
    "\n",
    "      if not is_english(clean_body):\n",
    "        continue\n",
    "\n",
    "      comments.append({\n",
    "        'comment_id': comment.id,\n",
    "        'body': clean_body,\n",
    "        'author': comment.author.name if comment.author else \"[deleted]\",\n",
    "        'author_role': comment.distinguished,\n",
    "        'score': comment.score,\n",
    "        'created_utc': comment.created_utc,\n",
    "        'is_submitter': comment.is_submitter,\n",
    "        'parent_id': comment.parent_id,\n",
    "        'permalink': comment.permalink\n",
    "      })\n",
    "\n",
    "    if comments:\n",
    "      sub_comments += len(comments)\n",
    "      total_comments += len(comments)\n",
    "\n",
    "      post = {\n",
    "        'post_id': submission.id,\n",
    "        'title': clean_text(submission.title),\n",
    "        'selftext': clean_text(submission.selftext),\n",
    "        'author': submission.author.name if submission.author else \"[deleted]\",\n",
    "        'author_role': submission.distinguished,\n",
    "        'score': submission.score,\n",
    "        'upvote_ratio': submission.upvote_ratio,\n",
    "        # 'url': submission.url,\n",
    "        'created_utc': submission.created_utc,\n",
    "        'num_comments': len(comments),\n",
    "        'subreddit': submission.subreddit.display_name,\n",
    "        'flair': submission.link_flair_text,\n",
    "        'is_self': submission.is_self,\n",
    "        'nsfw': submission.over_18,\n",
    "        'permalink': submission.permalink,\n",
    "        'comments': comments\n",
    "      }\n",
    "      posts_data.append(post)\n",
    "\n",
    "  print(f\"{sub_comments} comments collected from r/{sub_name}\")\n",
    "\n",
    "with open('raw_posts.json', 'w', encoding='utf-8') as f:\n",
    "  json.dump(posts_data, f, indent = 2, ensure_ascii=False)\n",
    "\n",
    "print(f\"\\nScraped {len(posts_data)} posts with {total_comments} comments.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25152a39",
   "metadata": {},
   "source": [
    "### DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b43f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('raw_posts.json', 'r', encoding='utf-8') as f:\n",
    "  raw_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4d78e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "cleaned_data = []\n",
    "total_cleaned_posts = 0\n",
    "total_cleaned_comments = 0\n",
    "mod_keywords = ['announcement', 'rules', 'mod', 'moderator', 'admin', 'clarification', 'faq', 'meta', 'update', 'policy']\n",
    "\n",
    "def format_datetime(utc_timestamp):\n",
    "  return datetime.fromtimestamp(utc_timestamp, tz=timezone.utc).isoformat()\n",
    "\n",
    "def is_meaningful(text):\n",
    "  if len(text) < 20:                      # Remove short comments\n",
    "    return False\n",
    "  if not any(c.isalpha() for c in text):  # Must contain alphabetic characters\n",
    "    return False\n",
    "  if len(text) > 2000:                    # remove very long comments \n",
    "    return False\n",
    "  return True\n",
    "\n",
    "for post in raw_data:\n",
    "  cleaned_post = {\n",
    "    'post_id': post['post_id'],\n",
    "    'title': post['title'],\n",
    "    'selftext': post['selftext'],\n",
    "    'author': post['author'],\n",
    "    'author_role': post['author_role'],\n",
    "    'score': post['score'],\n",
    "    'upvote_ratio': post['upvote_ratio'],\n",
    "    'created_utc': format_datetime(post['created_utc']),\n",
    "    'num_comments': 0,\n",
    "    'subreddit': post['subreddit'],\n",
    "    'flair': post['flair'],\n",
    "    'is_self': post['is_self'],\n",
    "    'nsfw': post['nsfw'],\n",
    "    'permalink': post['permalink'],\n",
    "    'comments': []\n",
    "  }\n",
    "\n",
    "  for comment in post['comments']:\n",
    "    if comment['body'] == \"\":\n",
    "      continue\n",
    "    if comment['author'] == \"[deleted]\":\n",
    "      continue\n",
    "    if not is_meaningful(comment['body']):\n",
    "      continue\n",
    "\n",
    "    cleaned_comment = {\n",
    "      'comment_id': comment['comment_id'],\n",
    "      'body': comment['body'],\n",
    "      'author': comment['author'],\n",
    "      'author_role': comment['author_role'],\n",
    "      'score': comment['score'],\n",
    "      'created_utc': format_datetime(comment['created_utc']),\n",
    "      'is_submitter': comment['is_submitter'],\n",
    "      'parent_id': comment['parent_id'],\n",
    "      'permalink': comment['permalink']\n",
    "    }\n",
    "    cleaned_post['comments'].append(cleaned_comment)\n",
    "\n",
    "  if cleaned_post['comments']:\n",
    "    cleaned_post['num_comments'] = len(cleaned_post['comments'])\n",
    "    total_cleaned_posts += 1\n",
    "    total_cleaned_comments += len(cleaned_post['comments'])\n",
    "    cleaned_data.append(cleaned_post)\n",
    "\n",
    "with open('cleaned_posts.json', 'w', encoding='utf-8') as f:\n",
    "  json.dump(cleaned_data, f, indent = 2, ensure_ascii = False)\n",
    "\n",
    "print(f\"Data cleaned. {total_cleaned_posts} posts remaining with {total_cleaned_comments} comments.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77acf31d",
   "metadata": {},
   "source": [
    "### SQL LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84624944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "  host = \"127.0.0.1\",\n",
    "  user = \"postgres\",\n",
    "  password = \"SqlPassword\",\n",
    "  dbname = \"reddit_data\",\n",
    "  port = \"5432\"\n",
    ")\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81babb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('cleaned_posts.json', 'r', encoding = 'utf-8') as f:\n",
    "  data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7999c8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "\n",
    "flair_category = {\n",
    "  \"Advice Needed\": \"Support\",\n",
    "  \"Need Support\": \"Support\",\n",
    "  \"Needs A Hug/Support\": \"Support\",\n",
    "  \"Venting\": \"Support\",\n",
    "  \"Medication\": \"Support\",\n",
    "  \"Therapy\": \"Support\",\n",
    "  \n",
    "  \"Anxiety Resource\": \"Mental Health Challenges\",\n",
    "  \"Content Warning: Suicidal Thoughts / Self Harm\": \"Mental Health Challenges\",\n",
    "  \"Content Warning: Eating Disorders\": \"Mental Health Challenges\",\n",
    "  \"Content Warning: Sexual Assault\": \"Mental Health Challenges\",\n",
    "  \"Content Warning: Violence\": \"Mental Health Challenges\",\n",
    "  \"Content Warning: Addiction / Substance Abuse\": \"Mental Health Challenges\",\n",
    "  \"Trigger Warning\": \"Mental Health Challenges\",\n",
    "  \"Sadness / Grief\": \"Mental Health Challenges\",\n",
    "  \n",
    "  \"Inspiration / Encouragement\": \"Positive Experiences\",\n",
    "  \"Good News / Happy\": \"Positive Experiences\",\n",
    "  \"Share Your Victories\": \"Positive Experiences\",\n",
    "  \"Uplifting\": \"Positive Experiences\",\n",
    "  \"Progress!\": \"Positive Experiences\",\n",
    "\n",
    "  \"DAE Questions\": \"Community Questions\",\n",
    "  \"Question\": \"Community Questions\",\n",
    "  \"Opinion / Thoughts\": \"Community Questions\",\n",
    "  \n",
    "  \"Work/School\": \"Life Experiences\",\n",
    "  \"Driving\": \"Life Experiences\",\n",
    "  \"Lifestyle\": \"Life Experiences\",\n",
    "  \"Travel\": \"Life Experiences\",\n",
    "  \"Sleep\": \"Life Experiences\",\n",
    "  \"Health\": \"Life Experiences\",\n",
    "  \"Family/Relationship\": \"Life Experiences\",\n",
    "  \n",
    "  \"Helpful Tips!\": \"Resources\",\n",
    "  \"Resources\": \"Resources\",\n",
    "  \"Research Study\": \"Resources\",\n",
    "  \n",
    "  \"Diary Entry\": \"Personal Expression\",\n",
    "  \"Introduction\": \"Personal Expression\",\n",
    "  \"Poetry\": \"Personal Expression\",\n",
    "  \"Discussion\": \"Personal Expression\"\n",
    "}\n",
    "\n",
    "def unique_topic(flair):\n",
    "  cur.execute(\"\"\"\n",
    "    INSERT INTO dim_topic (topic_label, flair)\n",
    "    VALUES (%s, %s)\n",
    "    ON CONFLICT (flair) DO NOTHING\n",
    "    RETURNING topic_id;\n",
    "  \"\"\", (flair_category.get(flair, \"Other\"), flair))\n",
    "  result = cur.fetchone()\n",
    "  if not result:\n",
    "    cur.execute(\"SELECT topic_id FROM dim_topic WHERE flair = %s;\", (flair,))\n",
    "    result = cur.fetchone()\n",
    "  return result[0]\n",
    "\n",
    "def unique_date_id(dt):\n",
    "  cur.execute(\"\"\"\n",
    "    INSERT INTO dim_date (full_date, year, quarter, month, day, weekday)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s)\n",
    "    ON CONFLICT (full_date) DO NOTHING\n",
    "    RETURNING date_id;\n",
    "  \"\"\", (dt.date(), dt.year, ((dt.month - 1) // 3 + 1), dt.month, dt.day, dt.strftime('%A')))\n",
    "  result = cur.fetchone()\n",
    "  if not result:\n",
    "    cur.execute(\"SELECT date_id FROM dim_date WHERE full_date = %s;\", (dt.date(),))\n",
    "    result = cur.fetchone()\n",
    "  return result[0]\n",
    "\n",
    "for post in data:\n",
    "  cur.execute(\"\"\"\n",
    "    INSERT INTO dim_posts (post_id, title, selftext, author, author_role, score, upvote_ratio, created_utc, num_comments, subreddit, is_self, nsfw, permalink)\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s);\n",
    "    \"\"\", (post['post_id'], post['title'], post['selftext'], post['author'], post['author_role'], post['score'], post['upvote_ratio'], post['created_utc'], post['num_comments'], post['subreddit'], post['is_self'], post['nsfw'], post['permalink'])\n",
    "  )\n",
    "\n",
    "  topic_id = unique_topic(post['flair'])\n",
    "\n",
    "  for comment in post['comments']:\n",
    "    cur.execute(\"\"\"\n",
    "      INSERT INTO dim_comment (comment_id, author, author_role, body, score, created_utc, is_submitter, parent_id, permalink)\n",
    "      VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s);\n",
    "      \"\"\", (comment['comment_id'], comment['author'], comment['author_role'], comment['body'], comment['score'], comment['created_utc'], comment['is_submitter'], comment['parent_id'], comment['permalink'])\n",
    "    )\n",
    "\n",
    "    dt = datetime.fromisoformat(comment['created_utc'])\n",
    "    date_id = unique_date_id(dt)\n",
    "\n",
    "    cur.execute(\"\"\"\n",
    "      INSERT INTO fact_table (comment_id, post_id, topic_id, date_id, is_submitter, comment_score, comment_length)\n",
    "      VALUES (%s, %s, %s, %s, %s, %s, %s);\n",
    "      \"\"\", (comment['comment_id'], post['post_id'], topic_id, date_id, comment['is_submitter'], comment['score'], len(comment['body']))\n",
    "    )\n",
    "\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb361c1f",
   "metadata": {},
   "source": [
    "### TOPIC MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558988be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "  host = \"127.0.0.1\",\n",
    "  user = \"postgres\",\n",
    "  password = \"SqlPassword\",\n",
    "  dbname = \"reddit_data\",\n",
    "  port = \"5432\"\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Load comments\n",
    "df = pd.read_sql_query(\"SELECT comment_id, body FROM dim_comment;\", conn)\n",
    "\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "# Load spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "# vague nouns\n",
    "exclude_words = {\"thing\", \"day\", \"time\", \"know\", \"go\", \"way\", \"lot\", \"people\", \"person\", \"life\", \"year\"}\n",
    "\n",
    "# Lemmatize and clean\n",
    "def lemmatize(text):\n",
    "  doc = nlp(text)\n",
    "  return \" \".join([\n",
    "    token.lemma_ for token in doc\n",
    "    if not token.is_stop\n",
    "    and token.is_alpha                              # remove punctuation/numbers\n",
    "    and token.pos_ in {\"NOUN\", \"ADJ\", \"VERB\"}       # only useful words\n",
    "    and token.lemma_.lower() not in exclude_words\n",
    "  ])\n",
    "\n",
    "# preprocessing\n",
    "df[\"cleaned_body\"] = df[\"body\"].astype(str).apply(lemmatize)\n",
    "documents = df[\"cleaned_body\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05513a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "\n",
    "# Seed list helps guide the model\n",
    "seed_topics = [\n",
    "  [\"anxiety\", \"panic\", \"attack\", \"worry\", \"overwhelm\", \"nervous\", \"overthink\", \"fear\", \"restless\", \"sweat\", \"tremble\", \"rush\", \"heart\", \"fast\", \"trigger\", \"phobia\", \"chest\", \"tight\", \"breathe\"],\n",
    "  [\"depression\", \"sad\", \"sadness\", \"hopeless\", \"suicide\", \"worthless\", \"fatigue\", \"empty\", \"cry\", \"sleep\", \"numb\", \"tired\", \"low\", \"dark\", \"alone\", \"disappear\", \"fail\", \"useless\", \"blame\", \"quiet\"],\n",
    "  [\"therapy\", \"talk\", \"counselor\", \"counseling\", \"cbt\", \"session\", \"support\", \"appointment\", \"therapist\", \"diagnose\", \"treatment\", \"professional\", \"cope\", \"relate\", \"progress\", \"discuss\", \"help\", \"listen\", \"recover\", \"resource\"]\n",
    "]\n",
    "\n",
    "# Fit model\n",
    "topic_model = BERTopic(\n",
    "  language=\"english\",\n",
    "  nr_topics=3,\n",
    "  seed_topic_list=seed_topics,\n",
    "  calculate_probabilities=True,\n",
    "  verbose=True\n",
    ")\n",
    "topics, probs = topic_model.fit_transform(documents)\n",
    "# Inspect topic keywords\n",
    "topic_info = topic_model.get_topic_info()\n",
    "print(topic_info)\n",
    "\n",
    "for i in range(3):\n",
    "  print(f\"\\nTopic {i}:\")\n",
    "  print(topic_model.get_topic(i - 1))\n",
    "\n",
    "df[\"topic_id\"] = topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e341179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "  host = \"127.0.0.1\",\n",
    "  user = \"postgres\",\n",
    "  password = \"SqlPassword\",\n",
    "  dbname = \"reddit_data\",\n",
    "  port = \"5432\"\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "  cur.execute(\"\"\"\n",
    "    UPDATE fact_table SET topic_classification = %s WHERE comment_id = %s;\n",
    "    \"\"\", (row['topic_id'] + 1, row['comment_id'])\n",
    "  )\n",
    "\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
